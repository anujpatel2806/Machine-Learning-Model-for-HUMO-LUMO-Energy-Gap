# -*- coding: utf-8 -*-
"""HOMO - LUMO Energy ML Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zUTk4_-nGJWehASy45G1dMDEMUOR0QLv

# **Machine Learning Model for HOMO - LUMO Energy Gap using Molecular Descriptors**

# HOMO-LUMO Energy Gap Prediction using RDKit Molecular descriptors<br>
<b>HOMO</b> stands for <i>highest occupied molecular orbital</i> and <b>LUMO</b> stands for <i> lowest unoccupied molecular orbital</i>. HOMO-LUMO molecular orbitals are called frontier molecular orbitals. They are involved in chemical bond formation. Especially, pericyclic reactions such as cycloaddition, electrocyclic reactions, and sigmatropic rearrangement are explained using HOMO-LUMO molecular orbitals. In addition, in UV-Visible spectroscopy, the absorbance of organic molecules that have extended conjugated double bonds can be rationalized using the HOMO-LUMO energy gap of the molecules.

Explanation - https://chem.libretexts.org/Bookshelves/Organic_Chemistry/Organic_Chemistry_(LibreTexts)/14%3A_Conjugated_Compounds_and_Ultraviolet_Spectroscopy/14.07%3A_Structure_Determination_in_Conjugated_Systems-_Ultraviolet_Spectroscopy
<div>
    <img src="https://github.com/gashawmg/RDKit-descriptors-for-HOMO-LUMO-energy-gap-prediction/blob/main/plainHOMO-LUMOEnegygap%20.jpg?raw=1" width="400")>
</div>

## **Data Set Source:-**

https://zivgitlab.uni-muenster.de/m_kueh11/fp-dm-tool

https://www.sciencedirect.com/science/article/pii/S2451929420300851#fig4

## **Molecular Descriptors**
"""

import warnings
warnings.filterwarnings("ignore")

import pandas as pd

import numpy as np

df = pd.read_csv('Orbital_Energies_input_data.csv')
df

df.shape

"""## **Canonical Smile**"""

!pip install rdkit-pypi

from rdkit import Chem

def canonical_smiles(smiles):
  mols = [Chem.MolFromSmiles(smi) for smi in smiles]
  smiles = [Chem.MolToSmiles(mol) for mol in mols]
  return smiles

"""### **Trial and Check for MolFromSmiles function:-**"""

from rdkit.Chem import Draw
from rdkit.Chem.Draw import IPythonConsole

a = Chem.MolFromSmiles('C=C=CC')
a

b = Chem.MolFromSmiles('CC=C=C')
b

a==b

"""### **Trial and Check for canonical_smiles function:-**"""

c = canonical_smiles(['C=C=CC'])
c

d = canonical_smiles(['CC=C=C'])
d

c==d

"""### **Conclusion:- canonical_smiles function satisfies the requirement than the MolFromSmiles function**"""

Canon_Smiles = canonical_smiles(df['SMILES'])
Canon_Smiles

len(Canon_Smiles)

df['SMILES'] = Canon_Smiles
df

"""## **Drop Duplicate Values**"""

duplicate_smiles = df[df['SMILES'].duplicated()]['SMILES'].values
len(duplicate_smiles)

df[df['SMILES'].isin(duplicate_smiles)].sort_values(by=['SMILES'])

df_new = df.drop_duplicates(subset=['SMILES'])
df_new

import seaborn as sb

sb.displot(df_new.Energygap)

sb.boxplot(df_new.Energygap)

"""## **Molecular Descriptors using RDkit & Modred**"""

!pip install rdkit-pypi
!pip install mordred

from rdkit import Chem
from rdkit.Chem import AllChem, Descriptors
from rdkit.ML.Descriptors import MoleculeDescriptors

from mordred import Calculator, descriptors

def RDkit_descriptors(smiles):
  mols = [Chem.MolFromSmiles(i) for i in smiles]
  calc = MoleculeDescriptors.MolecularDescriptorCalculator([x[0] for x in Descriptors._descList])
  desc_names = calc.GetDescriptorNames()

  Mol_Descriptors = []
  for mol in mols:
        # Add hydrogens to molecules
        mol=Chem.AddHs(mol)
        # Calculate all descriptors for each molecule
        descriptors = calc.CalcDescriptors(mol)
        Mol_Descriptors.append(descriptors)
  return Mol_Descriptors,desc_names

Mol_Descriptors,desc_names = RDkit_descriptors(df_new['SMILES'])

df_descriptors = pd.DataFrame(Mol_Descriptors,columns=desc_names)
df_descriptors

"""## **Molecular Fingerprints**"""

def morgan_fpts(data):
    Morgan_fpts = []
    for i in data:
        mol = Chem.MolFromSmiles(i) 
        fpts =  AllChem.GetMorganFingerprintAsBitVect(mol,2,2048)
        mfpts = np.array(fpts)
        Morgan_fpts.append(mfpts)  
    return np.array(Morgan_fpts)

Morgan_Fpts = morgan_fpts(df_new['SMILES'])
Morgan_Fpts

Morgan_Fpts.shape

Morgan_Fingerprints = pd.DataFrame(Morgan_Fpts,columns=['Col_{}'.format(i) for i in range(Morgan_Fpts.shape[1])])
Morgan_Fingerprints

"""## **Descriptors Calculation using Modred-1826 Descriptors**"""

def All_Mordred_descriptors(data):
    calc = Calculator(descriptors, ignore_3D=False)
    mols = [Chem.MolFromSmiles(smi) for smi in data]
    
    df = calc.pandas(mols)
    return df

mordred_descriptors = All_Mordred_descriptors(df_new['SMILES'])

mordred_descriptors

"""## **Removal of Highly Correlated Features**"""

def remove_correlated_features(descriptors):
    # Calculate correlation
    correlated_matrix = descriptors.corr().abs()

    # Upper triangle of correlation matrix
    upper_triangle = correlated_matrix.where(np.triu(np.ones(correlated_matrix.shape),k=1).astype(np.bool))

    # Identify columns that have above 0.9 values of correlation
    to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] >= 0.9)]
    print(to_drop)
    descriptors_correlated_dropped = descriptors.drop(columns=to_drop, axis=1)
    return descriptors_correlated_dropped

df_descriptors_new = remove_correlated_features(df_descriptors)
df_descriptors_new

"""## **Removal of Low Variance Thresold**"""

from sklearn.feature_selection import VarianceThreshold

def remove_low_variance(input_data, threshold=0.1):
    selection = VarianceThreshold(threshold)
    selection.fit(input_data)
    return input_data[input_data.columns[selection.get_support(indices=True)]]

# Molecular Features
X = remove_low_variance(df_descriptors_new, threshold=0.1)
X

# Labels or Targets
Y = df_new.Energygap
Y

"""## **Train-Test Data Split (70/30)**"""

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.3,random_state=42)

"""## **Identify Best ML Model for this Data Set**"""

!pip install lazypredict

import lazypredict
from lazypredict.Supervised import LazyRegressor

lregs = LazyRegressor(verbose=0,ignore_warnings=True, custom_metric=None)
models, prediction_tests = lregs.fit(X_train, X_test, Y_train, Y_test)

prediction_tests

"""## **LGBMRegressor Model**"""

from lightgbm import LGBMRegressor

lgbm = LGBMRegressor()

lgbm_opt = LGBMRegressor(max_depth=5, min_samples_split=4, n_estimators= 800, max_features='auto')

# Train the model and predict the energy gap using X_test 
lgbm_opt.fit(X_train, Y_train)
lgbm_predict = lgbm_opt.predict(X_test)

"""## **HistGradientBoostingRegressor	Model**"""

from sklearn.ensemble import HistGradientBoostingRegressor

gbr = HistGradientBoostingRegressor()

gbr_opt = HistGradientBoostingRegressor(learning_rate= 0.22)

# Train the model and predict the energy gap using X_test 
gbr_opt.fit(X_train, Y_train)
gbr_predict = gbr_opt.predict(X_test)

"""## **Taking Average of Both the Optimized Models**"""

avg_predict = (lgbm_predict + gbr_predict)/2

from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

"""### **Mean Absolute Error**"""

# Model performance using MAE
MAE = mean_absolute_error(Y_test, avg_predict)
print('MAE:', MAE)

"""### **Actual vs Predicted**"""

df_model = pd.DataFrame()

df_model['Actual'] = np.array(Y_test)
df_model['Predicted'] = avg_predict

df_model

"""### **R^2**"""

# R^2 (coefficient of determination) regression score function: 
R2 =r2_score(Y_test, avg_predict)
print('R^2:', R2)

"""## **ML Model Set**"""

import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import seaborn as sb

sb.regplot(x=avg_predict, y=Y_test, line_kws={"lw":2,'ls':'--','color':'black',"alpha":0.7})
plt.xlabel('Predicted Energy gap', color='blue')
plt.ylabel('Observed Energy gap', color ='blue')
plt.title("Test Set", color='red')
plt.grid(alpha=0.2)
R2 = mpatches.Patch(label="R2={:04.2f}".format(R2))
MAE = mpatches.Patch(label="MAE={:04.2f}".format(MAE))
plt.legend(handles=[R2, MAE])

"""## **Saving the Model**"""

from sklearn.preprocessing import StandardScaler

import pickle
with open('lgbm_model.pkl','wb') as f:
          pickle.dump(lgbm_opt,f)
        
with open('hgbr_model.pkl','wb') as f:
          pickle.dump(gbr_opt,f)

"""## **Loading the Model**"""

with open('lgbm_model.pkl','rb') as f:
       model_lgbm = pickle.load(f)
        
with open('hgbr_model.pkl','rb') as f:
    model_hgbr = pickle.load(f)